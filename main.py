from pyspark.sql import SparkSession

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Spark
spark = SparkSession.builder \
    .appName("PySpark Homework 3") \
    .getOrCreate()

print("‚úÖ SparkSession initialized")

# –®–ª—è—Ö –¥–æ CSV
DATA_PATH = "data/"

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è CSV-—Ñ–∞–π–ª—ñ–≤
users_df = spark.read.csv(DATA_PATH + "users.csv", header=True, inferSchema=True)
purchases_df = spark.read.csv(DATA_PATH + "purchases.csv", header=True, inferSchema=True)
products_df = spark.read.csv(DATA_PATH + "products.csv", header=True, inferSchema=True)

# –í–∏–≤–µ–¥–µ–Ω–Ω—è –ø–µ—Ä—à–∏—Ö —Ä—è–¥–∫—ñ–≤
print("üßë USERS")
users_df.show()

print("üõí PURCHASES")
purchases_df.show()

print("üì¶ PRODUCTS")
products_df.show()
